# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Provide the correct local file paths for both train and test datasets
train_file_path = "C:/Users/uppal/OneDrive/Desktop/gender_submission.csv"
test_file_path ="C:/Users/uppal/OneDrive/Desktop/gender_submission.csv"

# Load the Titanic training dataset
df_train = pd.read_csv(train_file_path)

# Load the Titanic test dataset (containing passenger information without survival details)
df_test = pd.read_csv(test_file_path)

# Display the first few rows of the training dataset
print(df_train.head())

# Display the first few rows of the test dataset
print(df_test.head())

# Data preprocessing for training set
X_train = df_train.drop('Survived', axis=1)
y_train = df_train['Survived']

# Data preprocessing for test set
X_test = df_test  # Assuming the test set does not contain the 'Survived' column

# Identify numerical and categorical features
numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns
categorical_features = X_train.select_dtypes(include=['object']).columns

# Create transformers for numerical and categorical features
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean'))
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('label_encoder', LabelEncoder())
])

# Combine transformers into a preprocessor using ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Split the data into training and testing sets
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# Create a Random Forest Classifier model
model = RandomForestClassifier(random_state=42)

# Train the model
model.fit(X_train_processed, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test_processed)

# Display the predictions
print("Predictions:")
print(y_pred)
